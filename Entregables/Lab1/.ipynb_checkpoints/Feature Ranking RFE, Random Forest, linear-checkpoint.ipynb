{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6ea51bc1-c7e6-5022-f91e-5933202f9f3a",
    "_uuid": "cde1f7416981edcc7951bbc7a4928933b7ba3760"
   },
   "source": [
    "#INTRODUCTION \n",
    "\n",
    "**Caveat** : Running this notebook will take a while if you do decide to fork so take note. A handful of minutes.\n",
    "\n",
    "This notebook will aim to provide an explanation and application of different feature ranking methods, namely that of Recursive Feature Elimination (RFE), Stability Selection, linear models as well as Random Forest. But first off, it is always imperative to give credit where credit is due. The stuff in this notebook is indebted to and borrows heavily from the excellent 4-part blog article by Ando Saabas on feature selection. So please do check out his article from this link: http://blog.datadive.net/selecting-good-features-part-iv-stability-selection-rfe-and-everything-side-by-side/ \n",
    "\n",
    "The contents of this notebook are as follows: \n",
    "\n",
    " 1. **Data Cleaning and Visualisation** : This section will revolve around exploring the data and visualising some summary statistics. \n",
    " 2. **Stability Selection via Randomised Lasso Method** : Introduce a relatively new feature selection method called \"Stability Selection\" and using the Randomised Lasso in its implementation\n",
    " 3. **Recursive Feature Elimination** : Implementing the Recursive Feature Elimination method of feature ranking via the use of basic Linear Regression \n",
    " 4. **Linear Model Feature Coefficients** : Implementing 3 of Sklearn's linear models (Linear Regression, Lasso and Ridge) and using the inbuilt estimated coefficients for our feature selection\n",
    " 5. **Random Forest Feature Selection** : Using the Random Forest's convenient attribute \"feature_importances\" to calculate and ultimately rank the feature importance.\n",
    "\n",
    "Finally, with all the points 1 to 5 above, we will combine the results to create our:\n",
    "\n",
    "**Feature Ranking Matrix** : Matrix of all the features along with the respective model scores which we can use in our ranking.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "15b3d941-c4a4-4c3f-bef1-4c4fcce4a33a",
    "_uuid": "8e0e4f54f2e722ae2cbf175d284d3a3cc0baf024"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.feature_selection import RFE, f_regression\n",
    "from sklearn.linear_model import (LinearRegression, Ridge, Lasso, RandomizedLasso)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2b932325-d368-ee17-75cb-40feb7e8d1bf",
    "_uuid": "5c3eb6eb38eb2cb7a119a52df82845d57d815a98"
   },
   "source": [
    "# 1. DATA CLEANSING AND ANALYSIS\n",
    "\n",
    "Let's first read in the house data as a dataframe \"house\" and inspect the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "1ca75509-383d-c6f5-d809-8a0e99b4e844",
    "_uuid": "ee8644c1339dc96ddffb9dea31086f76624e26eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view     ...      grade  sqft_above  \\\n",
       "0      5650     1.0           0     0     ...          7        1180   \n",
       "1      7242     2.0           0     0     ...          7        2170   \n",
       "2     10000     1.0           0     0     ...          6         770   \n",
       "3      5000     1.0           0     0     ...          7        1050   \n",
       "4      8080     1.0           0     0     ...          8        1680   \n",
       "\n",
       "   sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0              0      1955             0    98178  47.5112 -122.257   \n",
       "1            400      1951          1991    98125  47.7210 -122.319   \n",
       "2              0      1933             0    98028  47.7379 -122.233   \n",
       "3            910      1965             0    98136  47.5208 -122.393   \n",
       "4              0      1987             0    98074  47.6168 -122.045   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0           1340        5650  \n",
       "1           1690        7639  \n",
       "2           2720        8062  \n",
       "3           1360        5000  \n",
       "4           1800        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house = pd.read_csv(\"input/kc_house_data.csv\")\n",
    "house.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "78ba4e90-1d29-ae62-9fc5-ad0b590a1845",
    "_uuid": "58414416d02484843c6466f0dd754c08877f0e55"
   },
   "source": [
    "Now its time for some general data inspection. Let's first examine to see if there are any nulls in the dataframe as well as look at the type of the data (i.e whether it is a string or numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "cb6e65da-ba74-0ffe-828d-ebf7db2b1c07",
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "_uuid": "d15d597083b8c89ff9999f4fd50a4af64df3e021"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id               False\n",
      "date             False\n",
      "price            False\n",
      "bedrooms         False\n",
      "bathrooms        False\n",
      "sqft_living      False\n",
      "sqft_lot         False\n",
      "floors           False\n",
      "waterfront       False\n",
      "view             False\n",
      "condition        False\n",
      "grade            False\n",
      "sqft_above       False\n",
      "sqft_basement    False\n",
      "yr_built         False\n",
      "yr_renovated     False\n",
      "zipcode          False\n",
      "lat              False\n",
      "long             False\n",
      "sqft_living15    False\n",
      "sqft_lot15       False\n",
      "dtype: bool\n",
      "id                 int64\n",
      "date              object\n",
      "price            float64\n",
      "bedrooms           int64\n",
      "bathrooms        float64\n",
      "sqft_living        int64\n",
      "sqft_lot           int64\n",
      "floors           float64\n",
      "waterfront         int64\n",
      "view               int64\n",
      "condition          int64\n",
      "grade              int64\n",
      "sqft_above         int64\n",
      "sqft_basement      int64\n",
      "yr_built           int64\n",
      "yr_renovated       int64\n",
      "zipcode            int64\n",
      "lat              float64\n",
      "long             float64\n",
      "sqft_living15      int64\n",
      "sqft_lot15         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Looking for nulls\n",
    "print(house.isnull().any())\n",
    "# Inspecting type\n",
    "print(house.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "aa63409f-4adf-d8dc-c781-1217f87710d8",
    "_uuid": "d95e89ee405a134c45c0f36a3c8cfc9b3bec2fc8"
   },
   "source": [
    "The data is pretty clean. There are no pesky nulls which we need to treat and most of the features are in numeric format. Let's go ahead and drop the \"id\" and \"date\" columns as these 2 features will not be used in this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b6d0eee1-089e-e880-982a-a81d8f36a899",
    "_uuid": "cd35006e81ba37d1832711d82dcfe89b634802f8"
   },
   "outputs": [],
   "source": [
    "# Dropping the id and date columns\n",
    "house = house.drop(['id', 'date'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c0b6dced-bb93-bf29-2a27-4a5b0a05d185",
    "_uuid": "b5085a15f47eeca65b2999a3371230979751c288"
   },
   "source": [
    "**Pairplot Visualisation**\n",
    "\n",
    "Let's create some Seaborn pairplots for the features ('sqft_lot','sqft_above','price','sqft_living','bedrooms') to get a feel for how the various features are distributed vis-a-vis the price as well as the number of bedrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2a9dbedc-9be7-f89d-a855-f21738d72e17",
    "_uuid": "74c725f2563ccb6d1bd9fe35a85d36dfb9488d9c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sns.pairplot(house[['sqft_lot','sqft_above','price','sqft_living','bedrooms']], hue='bedrooms', palette='afmhot',size=1.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "75f73c02-1893-d98c-8d02-e1005b332741",
    "_uuid": "5c9d4f33f1b9aba86e5aae07db1a51ef875e4f0c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emser/Apps/anaconda3/lib/python3.6/site-packages/seaborn/axisgrid.py:2065: UserWarning: The `size` parameter has been renamed to `height`; pleaes update your code.\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/emser/Apps/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/home/emser/Apps/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/emser/Apps/anaconda3/lib/python3.6/site-packages/statsmodels/nonparametric/kde.py:488: RuntimeWarning: invalid value encountered in true_divide\n",
      "  binned = fast_linbin(X, a, b, gridsize) / (delta * nobs)\n",
      "/home/emser/Apps/anaconda3/lib/python3.6/site-packages/statsmodels/nonparametric/kdetools.py:34: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  FAC1 = 2*(np.pi*bw/RANGE)**2\n"
     ]
    }
   ],
   "source": [
    "with sns.plotting_context(\"notebook\",font_scale=2.5):\n",
    "    g = sns.pairplot(house[['sqft_lot','sqft_above','price','sqft_living','bedrooms']], \n",
    "                 hue='bedrooms', palette='tab20',size=6)\n",
    "g.set(xticklabels=[]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "222bcbc2-3f3d-9ca0-f30f-757206f923d5",
    "_uuid": "e7f9d812082c1de0ac06a05d5efa2be1b4cdeb3e"
   },
   "source": [
    "From the pairplots, we seem to get the classical linear distribution of the data points, for example with price against sqft_living. This bodes well as in the latter analysis, we will implement some linear models which we will use in our Feature ranking. Let's look at the correlation heatmap: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1d179a59-c663-ef84-c66f-cb8e43226a7c",
    "_uuid": "f2c6729c00b5f2be3cd522e96a4cacfb899a3e02",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str_list = [] # empty list to contain columns with strings (words)\n",
    "for colname, colvalue in house.iteritems():\n",
    "    if type(colvalue[1]) == str:\n",
    "         str_list.append(colname)\n",
    "# Get to the numeric columns by inversion            \n",
    "num_list = house.columns.difference(str_list) \n",
    "# Create Dataframe containing only numerical features\n",
    "house_num = house[num_list]\n",
    "f, ax = plt.subplots(figsize=(16, 12))\n",
    "plt.title('Pearson Correlation of features')\n",
    "# Draw the heatmap using seaborn\n",
    "#sns.heatmap(house_num.astype(float).corr(),linewidths=0.25,vmax=1.0, square=True, cmap=\"PuBuGn\", linecolor='k', annot=True)\n",
    "sns.heatmap(house_num.astype(float).corr(),linewidths=0.25,vmax=1.0, square=True, cmap=\"cubehelix\", linecolor='k', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fc3d8109-ebc5-264c-f964-04f66da0fec0",
    "_uuid": "a3668fbd5d02ee623aaf7f2cbc430c8301989db3"
   },
   "source": [
    "# 2. Stability Selection via Randomized Lasso\n",
    "\n",
    "In a nutshell, this method serves to apply the feature selection on different parts of the data and features repeatedly until the results can be aggregated. Therefore stronger features ( defined as being selected as important) will have greater scores in this method as compared to weaker features. Refer to this paper by Nicolai Meinshausen and Peter Buhlmann for a much greater detail on the method : http://stat.ethz.ch/~nicolai/stability.pdf\n",
    "\n",
    "In this notebook, the Stability Selection method is conveniently inbuilt into sklearn's randomized lasso model and therefore this will be implemented as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "45351992-0216-dd3d-76fe-4a658674f0c4",
    "_uuid": "f7b3717f89e357ee844277dde65f298fd2804276",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First extract the target variable which is our House prices\n",
    "Y = house.price.values\n",
    "# Drop price from the house dataframe and create a matrix out of the house data\n",
    "house = house.drop(['price'], axis=1)\n",
    "X = house.as_matrix()\n",
    "# Store the column/feature names into a list \"colnames\"\n",
    "colnames = house.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1c239bb6-b82e-e35b-7c3c-580c98094cce",
    "_uuid": "1a7926be983626aa6889161a19eee043eef24051"
   },
   "source": [
    "Next, we create a function which will be able to conveniently store our feature rankings obtained from the various methods described here into a Python dictionary. In case you are thinking I created this function, no this is not the case. All credit goes to Ando Saabas and I am only trying to apply what he has discussed in the context of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ecc7b17a-b6d5-7d6c-726d-de7b75c3c1eb",
    "_uuid": "c92f382f667f648e7679f4b8b48100dd56273119",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define dictionary to store our rankings\n",
    "ranks = {}\n",
    "# Create our function which stores the feature rankings to the ranks dictionary\n",
    "def ranking(ranks, names, order=1):\n",
    "    minmax = MinMaxScaler()\n",
    "    ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]\n",
    "    ranks = map(lambda x: round(x,2), ranks)\n",
    "    return dict(zip(names, ranks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a56e6fbf-1511-2ff7-0693-2f55aa0d21cd",
    "_uuid": "53bdbc76d42cb608da895a5f57f50d6a714bbb4d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finally let's run our Selection Stability method with Randomized Lasso\n",
    "rlasso = RandomizedLasso(alpha=0.04)\n",
    "rlasso.fit(X, Y)\n",
    "ranks[\"rlasso/Stability\"] = ranking(np.abs(rlasso.scores_), colnames)\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "15244118-31f5-e2df-8ce0-34a6d8f5c729",
    "_uuid": "e4620d40f9df515483eb62a507425f74345ca99f"
   },
   "source": [
    "# 3. Recursive Feature Elimination ( RFE )\n",
    "\n",
    "Now onto the next method in our feature ranking endeavour. Recursive Feature Elimination or RFE uses a model ( eg. linear Regression or SVM) to select either the best or worst-performing feature, and then excludes this feature. The whole process is then iterated until all features in the dataset are used up ( or up to a user-defined limit). Sklearn conveniently possesses a RFE function via the sklearn.feature_selection call and we will use this along with a simple linear regression model for our ranking search as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e11f8021-2f8b-074b-d0cc-c6d9d6d8ae8e",
    "_uuid": "f4c3fbbc4edeca6db3b183ed14790cb87f638c73",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct our Linear Regression model\n",
    "lr = LinearRegression(normalize=True)\n",
    "lr.fit(X,Y)\n",
    "#stop the search when only the last feature is left\n",
    "rfe = RFE(lr, n_features_to_select=1, verbose =3 )\n",
    "rfe.fit(X,Y)\n",
    "ranks[\"RFE\"] = ranking(list(map(float, rfe.ranking_)), colnames, order=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c6457163-f8c0-85a7-d69f-5ca2a880010f",
    "_uuid": "757117f801fb02d422a4e768e40a380e838e57df"
   },
   "source": [
    "# 4. Linear Model Feature Ranking\n",
    "\n",
    "Now let's apply 3 different linear models (Linear, Lasso and Ridge Regression) and how the features are selected and prioritised via these models. To achieve this, I shall use the sklearn implementation of these models and in particular the attribute .coef to return the estimated coefficients for each feature in the linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "64b0534b-c62a-7d85-e181-615b7a3743c9",
    "_uuid": "7eae3169285b35f76de75292ae4f6091c31960a9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using Linear Regression\n",
    "lr = LinearRegression(normalize=True)\n",
    "lr.fit(X,Y)\n",
    "ranks[\"LinReg\"] = ranking(np.abs(lr.coef_), colnames)\n",
    "\n",
    "# Using Ridge \n",
    "ridge = Ridge(alpha = 7)\n",
    "ridge.fit(X,Y)\n",
    "ranks['Ridge'] = ranking(np.abs(ridge.coef_), colnames)\n",
    "\n",
    "# Using Lasso\n",
    "lasso = Lasso(alpha=.05)\n",
    "lasso.fit(X, Y)\n",
    "ranks[\"Lasso\"] = ranking(np.abs(lasso.coef_), colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ee729bd0-270e-dc30-8fc8-b2d79873c4e1",
    "_uuid": "edb4e6e2625bb63f06d53dd9db73402a83575b9a"
   },
   "source": [
    "# 5. Random Forest feature ranking\n",
    "\n",
    "Sklearn's Random Forest model also comes with it's own inbuilt feature ranking attribute and one can conveniently just call it via \"feature_importances_\". That is what we will be using as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f013dad9-8855-530f-f792-48163dab2457",
    "_uuid": "f8ab99420883f6e3391bdb97048454c03e9c4f8a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_jobs=-1, n_estimators=50, verbose=3)\n",
    "rf.fit(X,Y)\n",
    "ranks[\"RF\"] = ranking(rf.feature_importances_, colnames);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "20ed4bd0-29b6-86a8-0bb8-cd34424376d5",
    "_uuid": "37dd6667f94db4526867b21b3375df16954610ef"
   },
   "source": [
    "# 6. Creating the Feature Ranking Matrix\n",
    "\n",
    "We combine the scores from the various methods above and output it in a matrix form for convenient viewing as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b6eb5b25-cc7e-f1eb-6a7b-8f591b7e560e",
    "_uuid": "e09a8414122d190ae530b4dcc8b59bf7c6a4d82a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create empty dictionary to store the mean value calculated from all the scores\n",
    "r = {}\n",
    "for name in colnames:\n",
    "    r[name] = round(np.mean([ranks[method][name] \n",
    "                             for method in ranks.keys()]), 2)\n",
    " \n",
    "methods = sorted(ranks.keys())\n",
    "ranks[\"Mean\"] = r\n",
    "methods.append(\"Mean\")\n",
    " \n",
    "print(\"\\t%s\" % \"\\t\".join(methods))\n",
    "for name in colnames:\n",
    "    print(\"%s\\t%s\" % (name, \"\\t\".join(map(str, \n",
    "                         [ranks[method][name] for method in methods]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5d9d44d0-fd8d-894e-657f-81762195499c",
    "_uuid": "4b68741c8ffc59327db34488273b990a5fa6c6aa"
   },
   "source": [
    "Now, with the matrix above, the numbers and layout does not seem very easy or pleasant to the eye. Therefore, let's just collate the mean ranking score attributed to each of the feature and plot that via Seaborn's factorplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "daae301e-e669-b2b6-6978-cbcad579696c",
    "_uuid": "d798434946ba4507b1138a5ece8647c757b763b9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put the mean scores into a Pandas dataframe\n",
    "meanplot = pd.DataFrame(list(r.items()), columns= ['Feature','Mean Ranking'])\n",
    "\n",
    "# Sort the dataframe\n",
    "meanplot = meanplot.sort_values('Mean Ranking', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2bdfa64e-d23d-d042-5e9d-080beb245ece",
    "_uuid": "3f78ab9b8271d36d4405ef83b3fac1609f2c6e2a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's plot the ranking of the features\n",
    "sns.factorplot(x=\"Mean Ranking\", y=\"Feature\", data = meanplot, kind=\"bar\", \n",
    "               size=14, aspect=1.9, palette='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7636811d-66b3-fa6d-a035-1b7874a1e30b",
    "_uuid": "958426edfb12efed1093e9a7fb9f5b969f4b455a"
   },
   "source": [
    "Well as you can see from our feature ranking endeavours, the top 3 features are 'lat', 'waterfront' and 'grade'. The bottom 3 are 'sqft_lot15', 'sqft_lot' and 'sqft_basement'. \n",
    "This sort of feature ranking can be really useful, especially if one has many many features in the dataset and would like to trim or cut off features that contribute negligibly."
   ]
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
